{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cee7404-22eb-4095-97b9-9a6bd87dbc6d",
   "metadata": {},
   "source": [
    "# convonutional neutral network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2da8328-b8b5-45bf-81a1-e9d2d3016251",
   "metadata": {},
   "source": [
    "# it is a artificial neural network which is widely used for image/object recognition and classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2c91571-3335-4f83-a709-00c0657c49e7",
   "metadata": {},
   "source": [
    "# for color images there is three color chanels of 1024 x 1024\n",
    "1 - Red\n",
    "2 - green\n",
    "3 - blue\n",
    "range of each pixel in three chanels is 0,255 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc66b063-88af-4ab9-851e-1ac8f4f59948",
   "metadata": {},
   "source": [
    "# working\n",
    "convolution --> Max pooling --> Flatting --> Full convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511defd1-72ee-47c0-8744-fe57153d235e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "af66a293-e093-4993-8a10-54cf55b0efeb",
   "metadata": {},
   "source": [
    "//convonution\n",
    "input data * kernel =  convoluted features/feature map\n",
    "(matrice)   (matrice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aef78f63-4bbb-48a1-abe1-ff69e711682f",
   "metadata": {},
   "source": [
    "// pooling\n",
    "its function is to progessively reduce the spatial size of the representation to reduce the amount of parameters and computations in network\n",
    "basically it reduce the size of a picture not affect its features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34351a5a-412b-4677-8853-79b2b924a3f3",
   "metadata": {},
   "source": [
    "// flatting is converting the data into one dimensional array for inputting it to next layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591ed2c-7eaa-441a-b5ba-dab1754b11e6",
   "metadata": {},
   "source": [
    "# practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2b8cd4-40aa-4099-bb77-ba48b5ccaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eed2fda-ebb9-46ce-8777-4c4097627872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed17cfe-5b24-4e8b-b12f-2c8eac862510",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac95134-bdcd-4cde-8a35-c2297bf12ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(32,(3,3),input_shape = (64,64,3),activation=\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(16,(3,3),activation=\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3617a3b-22a1-4d70-bd52-cfc7711a8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation=\"relu\"))\n",
    "cnn.add(Dense(32,activation=\"relu\"))\n",
    "cnn.add(Dense(16,activation=\"relu\"))\n",
    "cnn.add(Dense(8,activation=\"relu\"))\n",
    "cnn.add(Dense(4,activation=\"relu\"))\n",
    "cnn.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72a4185-cf7b-409e-b3b0-e084725dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66f2e8dd-17f6-4942-b1de-b40e4641cd94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 715ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 701ms/step - loss: 0.6919 - val_loss: 0.6909\n",
      "Epoch 3/10\n",
      "\u001b[1m47/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.6913"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x0000025F09EA5CB0>\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Roaming\\Python\\Python312\\site-packages\\PIL\\Image.py\", line 3339, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x0000025F09EA5CB0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2835]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m\n\u001b[0;32m      9\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     10\u001b[0m        \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBhakti Gajipara\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m        target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     12\u001b[0m        batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     13\u001b[0m        class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     16\u001b[0m        \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBhakti Gajipara\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesting_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m        target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     18\u001b[0m        batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     19\u001b[0m        class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x0000025F09EA5CB0>\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Bhakti Gajipara\\AppData\\Roaming\\Python\\Python312\\site-packages\\PIL\\Image.py\", line 3339, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x0000025F09EA5CB0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2835]"
     ]
    }
   ],
   "source": [
    " train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\Bhakti Gajipara\\OneDrive\\Documents\\data_set\\training_data\",\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\Bhakti Gajipara\\OneDrive\\Documents\\data_set\\testing_data\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator,steps_per_epoch=50,epochs=10,validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f7082-b900-4b8b-8b38-c70be72f34d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e293337-050b-469b-b71d-d3e83f60e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d16f619-83dc-4b1d-99e4-d795c2691333",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r\"C:\\Users\\Bhakti Gajipara\\Downloads\\testing\\images1.jpeg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13849707-dd72-46de-97af-14884a3d0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3106951-37c6-49f1-8b8b-e78034d082bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 55.,  70.,   3.],\n",
       "        [ 50.,  66.,   4.],\n",
       "        [ 46.,  66.,   3.],\n",
       "        ...,\n",
       "        [ 41.,  54.,   0.],\n",
       "        [ 45.,  58.,   2.],\n",
       "        [ 51.,  62.,   2.]],\n",
       "\n",
       "       [[ 50.,  65.,   0.],\n",
       "        [ 44.,  59.,   2.],\n",
       "        [ 43.,  63.,   2.],\n",
       "        ...,\n",
       "        [ 41.,  54.,   0.],\n",
       "        [ 45.,  58.,   2.],\n",
       "        [ 51.,  62.,   2.]],\n",
       "\n",
       "       [[ 47.,  61.,   2.],\n",
       "        [ 41.,  55.,   2.],\n",
       "        [ 41.,  60.,   5.],\n",
       "        ...,\n",
       "        [ 41.,  54.,   0.],\n",
       "        [ 45.,  58.,   2.],\n",
       "        [ 51.,  62.,   2.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[117., 141.,  19.],\n",
       "        [117., 144.,  29.],\n",
       "        [116., 147.,  30.],\n",
       "        ...,\n",
       "        [110., 139.,  33.],\n",
       "        [ 96., 126.,  14.],\n",
       "        [ 93., 126.,  13.]],\n",
       "\n",
       "       [[109., 140.,   2.],\n",
       "        [113., 141.,  18.],\n",
       "        [115., 143.,  24.],\n",
       "        ...,\n",
       "        [109., 138.,  30.],\n",
       "        [110., 138.,  38.],\n",
       "        [ 94., 123.,  15.]],\n",
       "\n",
       "       [[105., 136.,   0.],\n",
       "        [109., 138.,  12.],\n",
       "        [111., 139.,  18.],\n",
       "        ...,\n",
       "        [ 92., 121.,  11.],\n",
       "        [102., 130.,  28.],\n",
       "        [107., 136.,  28.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea0b53d0-6ec3-47f1-b060-f6e394b79cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a889dad-7e0c-4b7f-b2fa-79cf3053cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba84fce-84b6-4e60-a4bf-284f00161d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n"
     ]
    }
   ],
   "source": [
    "p = cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd01b9d-ed07-421e-8240-4cf6780ff219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "if p[0][0] < 0.5 :\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf6d76-a20e-49d0-a43b-6ebab7029330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
